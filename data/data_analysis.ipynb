{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mustard++_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SCENE           KEY                                           SENTENCE  \\\n",
      "0  1_10004  1_10004_c_00  Well, I'm sure that, uh, you...\\r\\nhave a lot ...   \n",
      "1  1_10004  1_10004_c_01                                        Who was he?   \n",
      "2  1_10004  1_10004_c_02  His name is Ron.\\r\\nI met him at my prayer group.   \n",
      "3  1_10004  1_10004_c_03          How long have you been involved with him?   \n",
      "4  1_10004  1_10004_c_04                                      A few months.   \n",
      "\n",
      "  END_TIME  SPEAKER SHOW  Sarcasm Sarcasm_Type Implicit_Emotion  \\\n",
      "0     0:06   PERSON  BBT      NaN          NaN              NaN   \n",
      "1     0:08  SHELDON  BBT      NaN          NaN              NaN   \n",
      "2     0:12   PERSON  BBT      NaN          NaN              NaN   \n",
      "3     0:14  SHELDON  BBT      NaN          NaN              NaN   \n",
      "4     0:16   PERSON  BBT      NaN          NaN              NaN   \n",
      "\n",
      "  Explicit_Emotion  Valence  Arousal  \n",
      "0              NaN      NaN      NaN  \n",
      "1              NaN      NaN      NaN  \n",
      "2              NaN      NaN      NaN  \n",
      "3              NaN      NaN      NaN  \n",
      "4              NaN      NaN      NaN  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PERSON' 'SHELDON' 'AMY' 'PENNY' 'RAJ' 'HOWARD' 'LEONARD' 'BERNADETTE'\n",
      " 'PERSON1' 'PERSON2' 'PERSON3' '-' 'OTHER' 'STUART' 'CHANDLER' 'MONICA'\n",
      " 'DOROTHY' 'ROSE' 'BLANCHE' 'ROSS' 'JOEY' 'RACHEL' 'PHOEBE' 'SOPHIA'\n",
      " 'SCOTT' 'MODERATOR' 'MEMBER-GIRL' 'MEMBER-BOY' 'GILFOYLE' 'ERLICH'\n",
      " 'DINESH' 'JARED' 'RICHARD']\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "speakers = df['SPEAKER'].unique()\n",
    "print(speakers)\n",
    "print(len(speakers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "female_speakers = ['AMY', 'PENNY','BERNADETTE', 'MONICA','DOROTHY', 'ROSE','RACHEL', 'PHOEBE', 'SOPHIA', 'MEMBER-GIRL', 'BLANCHE']\n",
    "print(len(female_speakers))\n",
    "male_speakers = ['SHELDON', 'RAJ', 'HOWARD', 'LEONARD', 'STUART', 'CHANDLER', 'ROSS', 'JOEY', 'SCOTT', 'MEMBER-BOY', 'GILFOYLE','ERLICH', 'DINESH', 'JARED', 'RICHARD']\n",
    "print(len(male_speakers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of female utterances: 1420\n",
      "Number of male utterances: 2836\n"
     ]
    }
   ],
   "source": [
    "female_speakers_df = df[df['SPEAKER'].isin(female_speakers)]\n",
    "male_speakers_df = df[df['SPEAKER'].isin(male_speakers)]\n",
    "\n",
    "female_utterances_count = female_speakers_df.shape[0]\n",
    "male_utterances_count = male_speakers_df.shape[0]\n",
    "\n",
    "print(f\"Number of female utterances: {female_utterances_count}\")\n",
    "print(f\"Number of male utterances: {male_utterances_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCENE</th>\n",
       "      <th>KEY</th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>SPEAKER</th>\n",
       "      <th>SHOW</th>\n",
       "      <th>Sarcasm</th>\n",
       "      <th>Sarcasm_Type</th>\n",
       "      <th>Implicit_Emotion</th>\n",
       "      <th>Explicit_Emotion</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1_10009</td>\n",
       "      <td>1_10009_c_00</td>\n",
       "      <td>FYI, we plan on selling out the human race hard.</td>\n",
       "      <td>0:02</td>\n",
       "      <td>AMY</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1_10009</td>\n",
       "      <td>1_10009_c_01</td>\n",
       "      <td>In 20 years, who knows what'll happen with any...</td>\n",
       "      <td>0:08</td>\n",
       "      <td>PENNY</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1_10009</td>\n",
       "      <td>1_10009_c_03</td>\n",
       "      <td>You do?</td>\n",
       "      <td>0:11</td>\n",
       "      <td>PENNY</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1_10009</td>\n",
       "      <td>1_10009_c_05</td>\n",
       "      <td>That's so sweet.</td>\n",
       "      <td>0:16</td>\n",
       "      <td>PENNY</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1_10009</td>\n",
       "      <td>1_10009_c_06</td>\n",
       "      <td>What the hell?! Excuse me?</td>\n",
       "      <td>0:17</td>\n",
       "      <td>AMY</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6023</th>\n",
       "      <td>3_S06E05_355</td>\n",
       "      <td>3_S06E05_355_c_1</td>\n",
       "      <td>I was quickly perusing your file--</td>\n",
       "      <td>0:03.874000</td>\n",
       "      <td>MONICA</td>\n",
       "      <td>SV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026</th>\n",
       "      <td>3_S06E05_355</td>\n",
       "      <td>3_S06E05_355_c_4</td>\n",
       "      <td>Wow. That... that's... super helpful.</td>\n",
       "      <td>0:13</td>\n",
       "      <td>MONICA</td>\n",
       "      <td>SV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6027</th>\n",
       "      <td>3_S06E05_355</td>\n",
       "      <td>3_S06E05_355_c_5</td>\n",
       "      <td>Thank you for that tip.</td>\n",
       "      <td>0:15.916000</td>\n",
       "      <td>MONICA</td>\n",
       "      <td>SV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6028</th>\n",
       "      <td>3_S06E05_355</td>\n",
       "      <td>3_S06E05_355_c_6</td>\n",
       "      <td>Um, anyway, yeah,</td>\n",
       "      <td>0:18</td>\n",
       "      <td>MONICA</td>\n",
       "      <td>SV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6029</th>\n",
       "      <td>3_S06E05_355</td>\n",
       "      <td>3_S06E05_355_c_7</td>\n",
       "      <td>I was just curious to know, like, what's it li...</td>\n",
       "      <td>0:22.749000</td>\n",
       "      <td>MONICA</td>\n",
       "      <td>SV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1420 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             SCENE               KEY  \\\n",
       "6          1_10009      1_10009_c_00   \n",
       "7          1_10009      1_10009_c_01   \n",
       "9          1_10009      1_10009_c_03   \n",
       "11         1_10009      1_10009_c_05   \n",
       "12         1_10009      1_10009_c_06   \n",
       "...            ...               ...   \n",
       "6023  3_S06E05_355  3_S06E05_355_c_1   \n",
       "6026  3_S06E05_355  3_S06E05_355_c_4   \n",
       "6027  3_S06E05_355  3_S06E05_355_c_5   \n",
       "6028  3_S06E05_355  3_S06E05_355_c_6   \n",
       "6029  3_S06E05_355  3_S06E05_355_c_7   \n",
       "\n",
       "                                               SENTENCE     END_TIME SPEAKER  \\\n",
       "6      FYI, we plan on selling out the human race hard.         0:02     AMY   \n",
       "7     In 20 years, who knows what'll happen with any...         0:08   PENNY   \n",
       "9                                               You do?         0:11   PENNY   \n",
       "11                                     That's so sweet.         0:16   PENNY   \n",
       "12                           What the hell?! Excuse me?         0:17     AMY   \n",
       "...                                                 ...          ...     ...   \n",
       "6023                 I was quickly perusing your file--  0:03.874000  MONICA   \n",
       "6026              Wow. That... that's... super helpful.         0:13  MONICA   \n",
       "6027                            Thank you for that tip.  0:15.916000  MONICA   \n",
       "6028                                  Um, anyway, yeah,         0:18  MONICA   \n",
       "6029  I was just curious to know, like, what's it li...  0:22.749000  MONICA   \n",
       "\n",
       "     SHOW  Sarcasm Sarcasm_Type Implicit_Emotion Explicit_Emotion  Valence  \\\n",
       "6     BBT      NaN          NaN              NaN              NaN      NaN   \n",
       "7     BBT      NaN          NaN              NaN              NaN      NaN   \n",
       "9     BBT      NaN          NaN              NaN              NaN      NaN   \n",
       "11    BBT      NaN          NaN              NaN              NaN      NaN   \n",
       "12    BBT      NaN          NaN              NaN              NaN      NaN   \n",
       "...   ...      ...          ...              ...              ...      ...   \n",
       "6023   SV      NaN          NaN              NaN              NaN      NaN   \n",
       "6026   SV      NaN          NaN              NaN              NaN      NaN   \n",
       "6027   SV      NaN          NaN              NaN              NaN      NaN   \n",
       "6028   SV      NaN          NaN              NaN              NaN      NaN   \n",
       "6029   SV      NaN          NaN              NaN              NaN      NaN   \n",
       "\n",
       "      Arousal  \n",
       "6         NaN  \n",
       "7         NaN  \n",
       "9         NaN  \n",
       "11        NaN  \n",
       "12        NaN  \n",
       "...       ...  \n",
       "6023      NaN  \n",
       "6026      NaN  \n",
       "6027      NaN  \n",
       "6028      NaN  \n",
       "6029      NaN  \n",
       "\n",
       "[1420 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_speakers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185\n",
      "189\n",
      "1420\n"
     ]
    }
   ],
   "source": [
    "female_speakers_df['Sarcasm']\n",
    "sarcastic_female_utterances = female_speakers_df[female_speakers_df['Sarcasm'] == False]\n",
    "non_sarcastic_female_utterances = female_speakers_df[female_speakers_df['Sarcasm'] == True]\n",
    "print(len(sarcastic_female_utterances))\n",
    "print(len(non_sarcastic_female_utterances))\n",
    "print(len(female_speakers_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n",
      "375\n",
      "2836\n"
     ]
    }
   ],
   "source": [
    "male_speakers_df['Sarcasm']\n",
    "sarcastic_male_utterances = male_speakers_df[male_speakers_df['Sarcasm'] == False]\n",
    "non_sarcastic_male_utterances = male_speakers_df[male_speakers_df['Sarcasm'] == True]\n",
    "print(len(sarcastic_male_utterances))\n",
    "print(len(non_sarcastic_male_utterances))\n",
    "print(len(male_speakers_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
