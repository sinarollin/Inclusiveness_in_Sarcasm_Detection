{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "\n",
    "df = pd.read_csv('mustard++_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCENE</th>\n",
       "      <th>KEY</th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>SPEAKER</th>\n",
       "      <th>SHOW</th>\n",
       "      <th>Sarcasm</th>\n",
       "      <th>Sarcasm_Type</th>\n",
       "      <th>Implicit_Emotion</th>\n",
       "      <th>Explicit_Emotion</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_10004</td>\n",
       "      <td>1_10004_c_00</td>\n",
       "      <td>Well, I'm sure that, uh, you...\\r\\nhave a lot ...</td>\n",
       "      <td>0:06</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_10004</td>\n",
       "      <td>1_10004_c_01</td>\n",
       "      <td>Who was he?</td>\n",
       "      <td>0:08</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_10004</td>\n",
       "      <td>1_10004_c_02</td>\n",
       "      <td>His name is Ron.\\r\\nI met him at my prayer group.</td>\n",
       "      <td>0:12</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_10004</td>\n",
       "      <td>1_10004_c_03</td>\n",
       "      <td>How long have you been involved with him?</td>\n",
       "      <td>0:14</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_10004</td>\n",
       "      <td>1_10004_c_04</td>\n",
       "      <td>A few months.</td>\n",
       "      <td>0:16</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>3_S06E06_143</td>\n",
       "      <td>3_S06E06_143_u</td>\n",
       "      <td>I thought that was the company policy-these days.</td>\n",
       "      <td>0:4.459000</td>\n",
       "      <td>GILFOYLE</td>\n",
       "      <td>SV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ILL</td>\n",
       "      <td>Frustration</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>3_S06E07_272</td>\n",
       "      <td>3_S06E07_272_c_0</td>\n",
       "      <td>When Richard told me about the dots last night...</td>\n",
       "      <td>0:08.708000</td>\n",
       "      <td>GILFOYLE</td>\n",
       "      <td>SV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>3_S06E07_272</td>\n",
       "      <td>3_S06E07_272_c_1</td>\n",
       "      <td>But a few hours later when I woke up in a stal...</td>\n",
       "      <td>0:13.917000</td>\n",
       "      <td>GILFOYLE</td>\n",
       "      <td>SV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>3_S06E07_272</td>\n",
       "      <td>3_S06E07_272_c_2</td>\n",
       "      <td>I realized something.</td>\n",
       "      <td>0:15.708000</td>\n",
       "      <td>GILFOYLE</td>\n",
       "      <td>SV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6040</th>\n",
       "      <td>3_S06E07_272</td>\n",
       "      <td>3_S06E07_272_u</td>\n",
       "      <td>That you're an alcoholic?</td>\n",
       "      <td>0:1.459000</td>\n",
       "      <td>DINESH</td>\n",
       "      <td>SV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ILL</td>\n",
       "      <td>Ridicule</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6041 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             SCENE               KEY  \\\n",
       "0          1_10004      1_10004_c_00   \n",
       "1          1_10004      1_10004_c_01   \n",
       "2          1_10004      1_10004_c_02   \n",
       "3          1_10004      1_10004_c_03   \n",
       "4          1_10004      1_10004_c_04   \n",
       "...            ...               ...   \n",
       "6036  3_S06E06_143    3_S06E06_143_u   \n",
       "6037  3_S06E07_272  3_S06E07_272_c_0   \n",
       "6038  3_S06E07_272  3_S06E07_272_c_1   \n",
       "6039  3_S06E07_272  3_S06E07_272_c_2   \n",
       "6040  3_S06E07_272    3_S06E07_272_u   \n",
       "\n",
       "                                               SENTENCE     END_TIME  \\\n",
       "0     Well, I'm sure that, uh, you...\\r\\nhave a lot ...         0:06   \n",
       "1                                           Who was he?         0:08   \n",
       "2     His name is Ron.\\r\\nI met him at my prayer group.         0:12   \n",
       "3             How long have you been involved with him?         0:14   \n",
       "4                                         A few months.         0:16   \n",
       "...                                                 ...          ...   \n",
       "6036  I thought that was the company policy-these days.   0:4.459000   \n",
       "6037  When Richard told me about the dots last night...  0:08.708000   \n",
       "6038  But a few hours later when I woke up in a stal...  0:13.917000   \n",
       "6039                              I realized something.  0:15.708000   \n",
       "6040                          That you're an alcoholic?   0:1.459000   \n",
       "\n",
       "       SPEAKER SHOW  Sarcasm Sarcasm_Type Implicit_Emotion Explicit_Emotion  \\\n",
       "0       PERSON  BBT      NaN          NaN              NaN              NaN   \n",
       "1      SHELDON  BBT      NaN          NaN              NaN              NaN   \n",
       "2       PERSON  BBT      NaN          NaN              NaN              NaN   \n",
       "3      SHELDON  BBT      NaN          NaN              NaN              NaN   \n",
       "4       PERSON  BBT      NaN          NaN              NaN              NaN   \n",
       "...        ...  ...      ...          ...              ...              ...   \n",
       "6036  GILFOYLE   SV      1.0          ILL      Frustration          Neutral   \n",
       "6037  GILFOYLE   SV      NaN          NaN              NaN              NaN   \n",
       "6038  GILFOYLE   SV      NaN          NaN              NaN              NaN   \n",
       "6039  GILFOYLE   SV      NaN          NaN              NaN              NaN   \n",
       "6040    DINESH   SV      1.0          ILL         Ridicule         Surprise   \n",
       "\n",
       "      Valence  Arousal  \n",
       "0         NaN      NaN  \n",
       "1         NaN      NaN  \n",
       "2         NaN      NaN  \n",
       "3         NaN      NaN  \n",
       "4         NaN      NaN  \n",
       "...       ...      ...  \n",
       "6036      4.0      7.0  \n",
       "6037      NaN      NaN  \n",
       "6038      NaN      NaN  \n",
       "6039      NaN      NaN  \n",
       "6040      4.0      6.0  \n",
       "\n",
       "[6041 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the gender classification for the dataset\n",
    "\n",
    "female_speakers = ['AMY', 'PENNY','BERNADETTE', 'MONICA','DOROTHY', 'ROSE','RACHEL', 'PHOEBE', 'SOPHIA', 'MEMBER-GIRL', 'BLANCHE']\n",
    "\n",
    "male_speakers = ['SHELDON', 'RAJ', 'HOWARD', 'LEONARD', 'STUART', 'CHANDLER', 'ROSS', 'JOEY', 'SCOTT', 'MEMBER-BOY', 'GILFOYLE','ERLICH', 'DINESH', 'JARED', 'RICHARD']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Formatting the dataset in the same way as in our original project\n",
    "\n",
    "# Initializing the dictionary for the final JSON structure\n",
    "json_data = {}\n",
    "\n",
    "# Processing each row independently to create the JSON structure\n",
    "for index, row in df.iterrows():\n",
    "    # Creating an entry for each utterance\n",
    "    entry = {\n",
    "        \"utterance\": row['SENTENCE'],\n",
    "        \"speaker\": row['SPEAKER'],\n",
    "        \"context\": [],                # We have no context information in this dataset (idea: same scene means context)\n",
    "        \"context_speakers\": [],       # We have no context information in this dataset (idea: same scene means context)\n",
    "        \"show\": row['SHOW'],\n",
    "        \"sarcasm\": bool(row['Sarcasm']) if pd.notnull(row['Sarcasm']) else False,\n",
    "        \"gender\": \"F\" if row['SPEAKER'] in female_speakers else \"M\" # Currently we also have \"Person\", might have to drop them from dataset as Gender is unknown. \n",
    "    }\n",
    "    \n",
    "    # Using the value in the 'KEY' column as the primary key for this JSON entry\n",
    "    json_data[row['KEY']] = entry\n",
    "\n",
    "# Converting to a JSON format\n",
    "json_output = json.dumps(json_data, indent=4)\n",
    "\n",
    "# Exporting to a JSON file\n",
    "with open('mustard++_formatted.json', 'w') as f:\n",
    "    f.write(json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping all data where speaker is \"PERSON\", as the gender is unkown. \n",
    "\n",
    "# Loading the JSON data from the file\n",
    "with open('mustard++_formatted.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Filtering out entries where the speaker is \"PERSON\"\n",
    "filtered_data = {key: value for key, value in data.items() if value['speaker'] != \"PERSON\"}\n",
    "\n",
    "# Saving the filtered data back to a new JSON file\n",
    "with open('mustard++_formatted_and_filtered.json', 'w') as f:\n",
    "    json.dump(filtered_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary to prepare for splitting of data\n",
    "\n",
    "*Female Utterances*\n",
    "> Sarcastic:        185\n",
    "> Non-Sarcastic:    189\n",
    "\n",
    "\n",
    "*Male Utterances*\n",
    "> Sarcastic:        360\n",
    "> Non-Sarcastic:    375\n",
    "\n",
    "**Female Only Model:**\n",
    "> 184 Sarcastic Female, 184 Non-Sarcastic Female\n",
    "\n",
    "**Male Only Model:**\n",
    "> 184 Sarcastic Male, 184 Non-Sarcastic Male\n",
    "\n",
    "**Mixed Model:**\n",
    "> 92 Sarcastic Male, 92 Non-Sarcastic Male, 92 Sarcastic Female, 92 Non-Sarcastic Female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the Female Dataset\n",
    "\n",
    "# Loading the formatted and filtered JSON data \n",
    "with open('mustard++_formatted_and_filtered.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Filtering entries where gender is \"F\" and sarcasm is TRUE\n",
    "filtered_entries_sarcastic = {key: value for key, value in data.items() if value.get('gender') == \"F\" and value.get('sarcasm') == True}\n",
    "\n",
    "# Ensuring that there are enough entries for sampling\n",
    "if len(filtered_entries_sarcastic) >= 184:\n",
    "    # Randomly selecting 184 entries\n",
    "    selected_entries_sarcastic = dict(random.sample(list(filtered_entries_sarcastic.items()), 184))\n",
    "else:\n",
    "    print(f\"Only {len(filtered_entries_sarcastic)} entries meet the criteria. Selecting all available entries.\")\n",
    "    selected_entries_sarcastic = filtered_entries_sarcastic\n",
    "\n",
    "# Filtering entries where gender is \"F\" and sarcasm is FALSE\n",
    "filtered_entries_non_sarcastic = {key: value for key, value in data.items() if value.get('gender') == \"F\" and value.get('sarcasm') == False}\n",
    "\n",
    "# Ensuring that there are enough entries for sampling\n",
    "if len(filtered_entries_non_sarcastic) >= 184:\n",
    "    # Randomly selecting 184 entries\n",
    "    selected_entries_non_sarcastic = dict(random.sample(list(filtered_entries_non_sarcastic.items()), 184))\n",
    "else:\n",
    "    print(f\"Only {len(filtered_entries_non_sarcastic)} entries meet the criteria. Selecting all available entries.\")\n",
    "    selected_entries_non_sarcastic = filtered_entries_non_sarcastic\n",
    "\n",
    "# Combining the selected sarcastic and non-sarcastic entries\n",
    "combined_entries = {**selected_entries_sarcastic, **selected_entries_non_sarcastic}\n",
    "\n",
    "# Saving the selected entries to a new JSON file\n",
    "with open('F_data.json', 'w') as f:\n",
    "    json.dump(combined_entries, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the Male dataset\n",
    "\n",
    "# Loading the formatted and filtered JSON data \n",
    "with open('mustard++_formatted_and_filtered.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Filtering entries where gender is \"M\" and sarcasm is TRUE\n",
    "filtered_entries_sarcastic = {key: value for key, value in data.items() if value.get('gender') == \"M\" and value.get('sarcasm') == True}\n",
    "\n",
    "# Ensuring that there are enough entries for sampling\n",
    "if len(filtered_entries_sarcastic) >= 184:\n",
    "    # Randomly selecting 184 entries\n",
    "    selected_entries_sarcastic = dict(random.sample(list(filtered_entries_sarcastic.items()), 184))\n",
    "else:\n",
    "    print(f\"Only {len(filtered_entries_sarcastic)} entries meet the criteria. Selecting all available entries.\")\n",
    "    selected_entries_sarcastic = filtered_entries_sarcastic\n",
    "\n",
    "# Filtering entries where gender is \"M\" and sarcasm is FALSE\n",
    "filtered_entries_non_sarcastic = {key: value for key, value in data.items() if value.get('gender') == \"M\" and value.get('sarcasm') == False}\n",
    "\n",
    "# Ensuring that there are enough entries for sampling\n",
    "if len(filtered_entries_non_sarcastic) >= 184:\n",
    "    # Randomly selecting 184 entries\n",
    "    selected_entries_non_sarcastic = dict(random.sample(list(filtered_entries_non_sarcastic.items()), 184))\n",
    "else:\n",
    "    print(f\"Only {len(filtered_entries_non_sarcastic)} entries meet the criteria. Selecting all available entries.\")\n",
    "    selected_entries_non_sarcastic = filtered_entries_non_sarcastic\n",
    "\n",
    "# Combining the selected sarcastic and non-sarcastic entries\n",
    "combined_entries = {**selected_entries_sarcastic, **selected_entries_non_sarcastic}\n",
    "\n",
    "# Saving the selected entries to a new JSON file\n",
    "with open('M_data.json', 'w') as f:\n",
    "    json.dump(combined_entries, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the Mixed Dataset\n",
    "# Comment: here we sample from the already created Male and Female datasets, to ensure the utterences selected are as similar as possible between the datasets. \n",
    "\n",
    "# Loading the male and female datasets\n",
    "with open('M_data.json', 'r') as f:\n",
    "    male_data = json.load(f)\n",
    "\n",
    "with open('F_data.json', 'r') as f:\n",
    "    female_data = json.load(f)\n",
    "\n",
    "# Filtering male entries\n",
    "sarcastic_male = {key: value for key, value in male_data.items() if value.get('sarcasm') == True}\n",
    "non_sarcastic_male = {key: value for key, value in male_data.items() if value.get('sarcasm') == False}\n",
    "\n",
    "# Filtering female entries\n",
    "sarcastic_female = {key: value for key, value in female_data.items() if value.get('sarcasm') == True}\n",
    "non_sarcastic_female = {key: value for key, value in female_data.items() if value.get('sarcasm') == False}\n",
    "\n",
    "# Randomly sampling 92 entries from each filtered group\n",
    "selected_sarcastic_male = dict(random.sample(list(sarcastic_male.items()), 92))\n",
    "selected_non_sarcastic_male = dict(random.sample(list(non_sarcastic_male.items()), 92))\n",
    "selected_sarcastic_female = dict(random.sample(list(sarcastic_female.items()), 92))\n",
    "selected_non_sarcastic_female = dict(random.sample(list(non_sarcastic_female.items()), 92))\n",
    "\n",
    "# Combining all selected entries into one dictionary\n",
    "mixed_entries = {\n",
    "    **selected_sarcastic_male,\n",
    "    **selected_non_sarcastic_male,\n",
    "    **selected_sarcastic_female,\n",
    "    **selected_non_sarcastic_female\n",
    "}\n",
    "\n",
    "# Saving the mixed dataset to a new JSON file\n",
    "with open('Mixed_data.json', 'w') as f:\n",
    "    json.dump(mixed_entries, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_data:\n",
      "Total entries: 368\n",
      "Male Sarcastic: 184\n",
      "Male Non-Sarcastic: 184\n",
      "Female Sarcastic: 0\n",
      "Female Non-Sarcastic: 0\n",
      "Contains duplicates: False\n",
      "\n",
      "F_data:\n",
      "Total entries: 368\n",
      "Male Sarcastic: 0\n",
      "Male Non-Sarcastic: 0\n",
      "Female Sarcastic: 184\n",
      "Female Non-Sarcastic: 184\n",
      "Contains duplicates: False\n",
      "\n",
      "Mixed_data:\n",
      "Total entries: 368\n",
      "Male Sarcastic: 92\n",
      "Male Non-Sarcastic: 92\n",
      "Female Sarcastic: 92\n",
      "Female Non-Sarcastic: 92\n",
      "Contains duplicates: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to load JSON data, analyze it, and print the results\n",
    "def analyze_json(file_path):\n",
    "    # Getting the dataset name from the file path\n",
    "    dataset_name = file_path.split('.')[0]  # Extracts the base name without extension\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Checking for duplicate keys\n",
    "    unique_keys = set(data.keys())\n",
    "    has_duplicates = len(unique_keys) < len(data)  # If unique keys are fewer than total keys, duplicates exist\n",
    "\n",
    "    total_entries = len(data)\n",
    "    sarcastic_male_count = sum(1 for value in data.values() if value.get('gender') == 'M' and value.get('sarcasm') == True)\n",
    "    non_sarcastic_male_count = sum(1 for value in data.values() if value.get('gender') == 'M' and value.get('sarcasm') == False)\n",
    "    sarcastic_female_count = sum(1 for value in data.values() if value.get('gender') == 'F' and value.get('sarcasm') == True)\n",
    "    non_sarcastic_female_count = sum(1 for value in data.values() if value.get('gender') == 'F' and value.get('sarcasm') == False)\n",
    "\n",
    "    # Printing the results directly in the function\n",
    "    print(f\"{dataset_name}:\")\n",
    "    print(f\"Total entries: {total_entries}\")\n",
    "    print(f\"Male Sarcastic: {sarcastic_male_count}\")\n",
    "    print(f\"Male Non-Sarcastic: {non_sarcastic_male_count}\")\n",
    "    print(f\"Female Sarcastic: {sarcastic_female_count}\")\n",
    "    print(f\"Female Non-Sarcastic: {non_sarcastic_female_count}\")\n",
    "    print(f\"Contains duplicates: {has_duplicates}\\n\")\n",
    "\n",
    "# Analyzing each dataset\n",
    "analyze_json('M_data.json')\n",
    "analyze_json('F_data.json')\n",
    "analyze_json('Mixed_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
