{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading JSON files\n",
    "folder = \"data/\"\n",
    "\n",
    "with open(folder + 'mixed_data.json') as f:\n",
    "    mixed_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary to prepare for splitting of data\n",
    "\n",
    "*Female Utterances*\n",
    "> Sarcastic:        185\n",
    "> Non-Sarcastic:    189\n",
    "\n",
    "\n",
    "*Male Utterances*\n",
    "> Sarcastic:        360\n",
    "> Non-Sarcastic:    375\n",
    "\n",
    "**Female Only Model:**\n",
    "> 184 Sarcastic Female, 184 Non-Sarcastic Female\n",
    "\n",
    "**Male Only Model:**\n",
    "> 184 Sarcastic Male, 184 Non-Sarcastic Male\n",
    "\n",
    "**Mixed Model:**\n",
    "> 92 Sarcastic Male, 92 Non-Sarcastic Male, 92 Sarcastic Female, 92 Non-Sarcastic Female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the Female Dataset\n",
    "\n",
    "data = mixed_data\n",
    "\n",
    "# Filtering entries where gender is \"F\" and sarcasm is TRUE\n",
    "filtered_entries_sarcastic = {key: value for key, value in data.items() if value.get('gender') == \"F\" and value.get('sarcasm') == True}\n",
    "\n",
    "# Ensuring that there are enough entries for sampling\n",
    "if len(filtered_entries_sarcastic) >= 184:\n",
    "    # Randomly selecting 184 entries\n",
    "    selected_entries_sarcastic = dict(random.sample(list(filtered_entries_sarcastic.items()), 184))\n",
    "else:\n",
    "    print(f\"Only {len(filtered_entries_sarcastic)} entries meet the criteria. Selecting all available entries.\")\n",
    "    selected_entries_sarcastic = filtered_entries_sarcastic\n",
    "\n",
    "# Filtering entries where gender is \"F\" and sarcasm is FALSE\n",
    "filtered_entries_non_sarcastic = {key: value for key, value in data.items() if value.get('gender') == \"F\" and value.get('sarcasm') == False}\n",
    "\n",
    "# Ensuring that there are enough entries for sampling\n",
    "if len(filtered_entries_non_sarcastic) >= 184:\n",
    "    # Randomly selecting 184 entries\n",
    "    selected_entries_non_sarcastic = dict(random.sample(list(filtered_entries_non_sarcastic.items()), 184))\n",
    "else:\n",
    "    print(f\"Only {len(filtered_entries_non_sarcastic)} entries meet the criteria. Selecting all available entries.\")\n",
    "    selected_entries_non_sarcastic = filtered_entries_non_sarcastic\n",
    "\n",
    "# Combining the selected sarcastic and non-sarcastic entries\n",
    "combined_entries = {**selected_entries_sarcastic, **selected_entries_non_sarcastic}\n",
    "\n",
    "# Saving the selected entries to a new JSON file\n",
    "with open(folder + 'F_data.json', 'w') as f:\n",
    "    json.dump(combined_entries, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the Male dataset\n",
    "\n",
    "# Filtering entries where gender is \"M\" and sarcasm is TRUE\n",
    "filtered_entries_sarcastic = {key: value for key, value in data.items() if value.get('gender') == \"M\" and value.get('sarcasm') == True}\n",
    "\n",
    "# Ensuring that there are enough entries for sampling\n",
    "if len(filtered_entries_sarcastic) >= 184:\n",
    "    # Randomly selecting 184 entries\n",
    "    selected_entries_sarcastic = dict(random.sample(list(filtered_entries_sarcastic.items()), 184))\n",
    "else:\n",
    "    print(f\"Only {len(filtered_entries_sarcastic)} entries meet the criteria. Selecting all available entries.\")\n",
    "    selected_entries_sarcastic = filtered_entries_sarcastic\n",
    "\n",
    "# Filtering entries where gender is \"M\" and sarcasm is FALSE\n",
    "filtered_entries_non_sarcastic = {key: value for key, value in data.items() if value.get('gender') == \"M\" and value.get('sarcasm') == False}\n",
    "\n",
    "# Ensuring that there are enough entries for sampling\n",
    "if len(filtered_entries_non_sarcastic) >= 184:\n",
    "    # Randomly selecting 184 entries\n",
    "    selected_entries_non_sarcastic = dict(random.sample(list(filtered_entries_non_sarcastic.items()), 184))\n",
    "else:\n",
    "    print(f\"Only {len(filtered_entries_non_sarcastic)} entries meet the criteria. Selecting all available entries.\")\n",
    "    selected_entries_non_sarcastic = filtered_entries_non_sarcastic\n",
    "\n",
    "# Combining the selected sarcastic and non-sarcastic entries\n",
    "combined_entries = {**selected_entries_sarcastic, **selected_entries_non_sarcastic}\n",
    "\n",
    "# Saving the selected entries to a new JSON file\n",
    "with open(folder + 'M_data.json', 'w') as f:\n",
    "    json.dump(combined_entries, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'M_data.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Creating the Mixed Dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Comment: here we sample from the already created Male and Female datasets, to ensure the utterences selected are as similar as possible between the datasets. \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Loading the male and female datasets\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mM_data.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      6\u001b[0m     male_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF_data.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'M_data.json'"
     ]
    }
   ],
   "source": [
    "## Creating the Mixed Dataset\n",
    "# Comment: here we sample from the already created Male and Female datasets, to ensure the utterences selected are as similar as possible between the datasets. \n",
    "\n",
    "# Loading the male and female datasets\n",
    "with open('M_data.json', 'r') as f:\n",
    "    male_data = json.load(f)\n",
    "\n",
    "with open('F_data.json', 'r') as f:\n",
    "    female_data = json.load(f)\n",
    "\n",
    "# Filtering male entries\n",
    "sarcastic_male = {key: value for key, value in male_data.items() if value.get('sarcasm') == True}\n",
    "non_sarcastic_male = {key: value for key, value in male_data.items() if value.get('sarcasm') == False}\n",
    "\n",
    "# Filtering female entries\n",
    "sarcastic_female = {key: value for key, value in female_data.items() if value.get('sarcasm') == True}\n",
    "non_sarcastic_female = {key: value for key, value in female_data.items() if value.get('sarcasm') == False}\n",
    "\n",
    "# Randomly sampling 92 entries from each filtered group\n",
    "selected_sarcastic_male = dict(random.sample(list(sarcastic_male.items()), 92))\n",
    "selected_non_sarcastic_male = dict(random.sample(list(non_sarcastic_male.items()), 92))\n",
    "selected_sarcastic_female = dict(random.sample(list(sarcastic_female.items()), 92))\n",
    "selected_non_sarcastic_female = dict(random.sample(list(non_sarcastic_female.items()), 92))\n",
    "\n",
    "# Combining all selected entries into one dictionary\n",
    "mixed_entries = {\n",
    "    **selected_sarcastic_male,\n",
    "    **selected_non_sarcastic_male,\n",
    "    **selected_sarcastic_female,\n",
    "    **selected_non_sarcastic_female\n",
    "}\n",
    "\n",
    "# Saving the mixed dataset to a new JSON file\n",
    "with open('Mixed_data.json', 'w') as f:\n",
    "    json.dump(mixed_entries, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/M_data:\n",
      "Total entries: 368\n",
      "Male Sarcastic: 184\n",
      "Male Non-Sarcastic: 184\n",
      "Female Sarcastic: 0\n",
      "Female Non-Sarcastic: 0\n",
      "Contains duplicates: False\n",
      "\n",
      "data/F_data:\n",
      "Total entries: 368\n",
      "Male Sarcastic: 0\n",
      "Male Non-Sarcastic: 0\n",
      "Female Sarcastic: 184\n",
      "Female Non-Sarcastic: 184\n",
      "Contains duplicates: False\n",
      "\n",
      "data/Mixed_data:\n",
      "Total entries: 1109\n",
      "Male Sarcastic: 360\n",
      "Male Non-Sarcastic: 375\n",
      "Female Sarcastic: 185\n",
      "Female Non-Sarcastic: 189\n",
      "Contains duplicates: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to load JSON data, analyze it, and print the results\n",
    "def analyze_json(file_path):\n",
    "    # Getting the dataset name from the file path\n",
    "    dataset_name = file_path.split('.')[0]  # Extracts the base name without extension\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Checking for duplicate keys\n",
    "    unique_keys = set(data.keys())\n",
    "    has_duplicates = len(unique_keys) < len(data)  # If unique keys are fewer than total keys, duplicates exist\n",
    "\n",
    "    total_entries = len(data)\n",
    "    sarcastic_male_count = sum(1 for value in data.values() if value.get('gender') == 'M' and value.get('sarcasm') == True)\n",
    "    non_sarcastic_male_count = sum(1 for value in data.values() if value.get('gender') == 'M' and value.get('sarcasm') == False)\n",
    "    sarcastic_female_count = sum(1 for value in data.values() if value.get('gender') == 'F' and value.get('sarcasm') == True)\n",
    "    non_sarcastic_female_count = sum(1 for value in data.values() if value.get('gender') == 'F' and value.get('sarcasm') == False)\n",
    "\n",
    "    # Printing the results directly in the function\n",
    "    print(f\"{dataset_name}:\")\n",
    "    print(f\"Total entries: {total_entries}\")\n",
    "    print(f\"Male Sarcastic: {sarcastic_male_count}\")\n",
    "    print(f\"Male Non-Sarcastic: {non_sarcastic_male_count}\")\n",
    "    print(f\"Female Sarcastic: {sarcastic_female_count}\")\n",
    "    print(f\"Female Non-Sarcastic: {non_sarcastic_female_count}\")\n",
    "    print(f\"Contains duplicates: {has_duplicates}\\n\")\n",
    "\n",
    "# Analyzing each dataset\n",
    "analyze_json(folder + 'M_data.json')\n",
    "analyze_json(folder + 'F_data.json')\n",
    "analyze_json(folder + 'Mixed_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the training, validation and test datasets\n",
    "\n",
    "# Female dataset\n",
    "female_sarcastic_utterances = [(key, value) for key, value in female_data.items() if value['sarcasm']]\n",
    "female_non_sarcastic_utterances = [(key, value) for key, value in female_data.items() if not value['sarcasm']]\n",
    "\n",
    "# Splitting the data into 70% training, 15% validation and 15% test\n",
    "FS_train, FS_test_val = train_test_split(female_sarcastic_utterances, test_size = 0.3)\n",
    "FS_test, FS_val = train_test_split(FS_test_val, test_size = 0.5)\n",
    "\n",
    "FnS_train, FnS_test_val = train_test_split(female_non_sarcastic_utterances, test_size = 0.3)\n",
    "FnS_test, FnS_val = train_test_split(FnS_test_val, test_size = 0.5)\n",
    "\n",
    "train_set_F = dict(FS_train + FnS_train)\n",
    "val_set_F = dict(FS_val + FnS_val)\n",
    "test_set_F = dict(FS_test + FnS_test)\n",
    "\n",
    "# Male dataset\n",
    "male_sarcastic_utterances = [(key, value) for key, value in male_data.items() if value['sarcasm']]\n",
    "male_non_sarcastic_utterances = [(key, value) for key, value in male_data.items() if not value['sarcasm']]\n",
    "\n",
    "# Splitting the data into 70% training, 15% validation and 15% test\n",
    "MS_train, MS_test_val = train_test_split(male_sarcastic_utterances, test_size = 0.3)\n",
    "MS_test, MS_val = train_test_split(MS_test_val, test_size = 0.5)\n",
    "\n",
    "MnS_train, MnS_test_val = train_test_split(male_non_sarcastic_utterances, test_size = 0.3)\n",
    "MnS_test, MnS_val = train_test_split(MnS_test_val, test_size = 0.5)\n",
    "\n",
    "train_set_M = dict(MS_train + MnS_train)\n",
    "val_set_M = dict(MS_val + MnS_val)\n",
    "test_set_M = dict(MS_test + MnS_test)\n",
    "\n",
    "# Mixed dataset\n",
    "mixed_F_sarcastic_utterances = [(key, value) for key, value in mixed_entries.items() if value['gender'] == 'F' and value['sarcasm']]\n",
    "mixed_F_non_sarcastic_utterances = [(key, value) for key, value in mixed_entries.items() if value['gender'] == 'F' and not value['sarcasm']]\n",
    "mixed_M_sarcastic_utterances = [(key, value) for key, value in mixed_entries.items() if value['gender'] == 'M' and value['sarcasm']]\n",
    "mixed_M_non_sarcastic_utterances = [(key, value) for key, value in mixed_entries.items() if value['gender'] == 'M' and not value['sarcasm']]\n",
    "\n",
    "# Splitting the data into 70% training, 15% validation and 15% test\n",
    "mixedS_F_train, mixedS_F_test_val = train_test_split(mixed_F_sarcastic_utterances, test_size = 0.3)\n",
    "mixedS_F_test, mixedS_F_val = train_test_split(mixedS_F_test_val, test_size = 0.5)\n",
    "\n",
    "mixednS_F_train, mixednS_F_test_val = train_test_split(mixed_F_non_sarcastic_utterances, test_size = 0.3)\n",
    "mixednS_F_test, mixednS_F_val = train_test_split(mixednS_F_test_val, test_size = 0.5)\n",
    "\n",
    "mixedS_M_train, mixedS_M_test_val = train_test_split(mixed_M_sarcastic_utterances, test_size = 0.3)\n",
    "mixedS_M_test, mixedS_M_val = train_test_split(mixedS_M_test_val, test_size = 0.5)\n",
    "\n",
    "mixednS_M_train, mixednS_M_test_val = train_test_split(mixed_M_non_sarcastic_utterances, test_size = 0.3)\n",
    "mixednS_M_test, mixednS_M_val = train_test_split(mixednS_M_test_val, test_size = 0.5)\n",
    "\n",
    "train_set_mixed = dict(mixedS_F_train + mixednS_F_train + mixedS_M_train + mixednS_M_train)\n",
    "val_set_mixed = dict(mixedS_F_val + mixednS_F_val + mixedS_M_val + mixednS_M_val)\n",
    "test_set_mixed = dict(mixedS_F_test + mixednS_F_test + mixedS_M_test + mixednS_M_test)\n",
    "\n",
    "# Saving the training, validation and test datasets to new JSON files\n",
    "with open(folder + 'train_M.json', 'w') as f:\n",
    "    json.dump(train_set_M, f, indent=4)\n",
    "\n",
    "with open(folder + 'val_M.json', 'w') as f:\n",
    "    json.dump(val_set_M, f, indent=4)\n",
    "\n",
    "with open(folder + 'test_M.json', 'w') as f:\n",
    "    json.dump(test_set_M, f, indent=4)\n",
    "\n",
    "with open(folder + 'train_F.json', 'w') as f:\n",
    "    json.dump(train_set_F, f, indent=4)\n",
    "\n",
    "with open(folder + 'val_F.json', 'w') as f:\n",
    "    json.dump(val_set_F, f, indent=4)\n",
    "\n",
    "with open(folder + 'test_F.json', 'w') as f:\n",
    "    json.dump(test_set_F, f, indent=4)\n",
    "\n",
    "with open(folder + 'train_mixed.json', 'w') as f:\n",
    "    json.dump(train_set_mixed, f, indent=4)\n",
    "\n",
    "with open(folder + 'val_mixed.json', 'w') as f:\n",
    "    json.dump(val_set_mixed, f, indent=4)\n",
    "\n",
    "with open(folder + 'test_mixed.json', 'w') as f:\n",
    "    json.dump(test_set_mixed, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train_M:\n",
      "Total entries: 256\n",
      "Male Sarcastic: 128\n",
      "Male Non-Sarcastic: 128\n",
      "Female Sarcastic: 0\n",
      "Female Non-Sarcastic: 0\n",
      "Contains duplicates: False\n",
      "\n",
      "data/val_M:\n",
      "Total entries: 56\n",
      "Male Sarcastic: 28\n",
      "Male Non-Sarcastic: 28\n",
      "Female Sarcastic: 0\n",
      "Female Non-Sarcastic: 0\n",
      "Contains duplicates: False\n",
      "\n",
      "data/test_M:\n",
      "Total entries: 56\n",
      "Male Sarcastic: 28\n",
      "Male Non-Sarcastic: 28\n",
      "Female Sarcastic: 0\n",
      "Female Non-Sarcastic: 0\n",
      "Contains duplicates: False\n",
      "\n",
      "data/train_F:\n",
      "Total entries: 256\n",
      "Male Sarcastic: 0\n",
      "Male Non-Sarcastic: 0\n",
      "Female Sarcastic: 128\n",
      "Female Non-Sarcastic: 128\n",
      "Contains duplicates: False\n",
      "\n",
      "data/val_F:\n",
      "Total entries: 56\n",
      "Male Sarcastic: 0\n",
      "Male Non-Sarcastic: 0\n",
      "Female Sarcastic: 28\n",
      "Female Non-Sarcastic: 28\n",
      "Contains duplicates: False\n",
      "\n",
      "data/test_F:\n",
      "Total entries: 56\n",
      "Male Sarcastic: 0\n",
      "Male Non-Sarcastic: 0\n",
      "Female Sarcastic: 28\n",
      "Female Non-Sarcastic: 28\n",
      "Contains duplicates: False\n",
      "\n",
      "data/train_mixed:\n",
      "Total entries: 256\n",
      "Male Sarcastic: 64\n",
      "Male Non-Sarcastic: 64\n",
      "Female Sarcastic: 64\n",
      "Female Non-Sarcastic: 64\n",
      "Contains duplicates: False\n",
      "\n",
      "data/val_mixed:\n",
      "Total entries: 56\n",
      "Male Sarcastic: 14\n",
      "Male Non-Sarcastic: 14\n",
      "Female Sarcastic: 14\n",
      "Female Non-Sarcastic: 14\n",
      "Contains duplicates: False\n",
      "\n",
      "data/test_mixed:\n",
      "Total entries: 56\n",
      "Male Sarcastic: 14\n",
      "Male Non-Sarcastic: 14\n",
      "Female Sarcastic: 14\n",
      "Female Non-Sarcastic: 14\n",
      "Contains duplicates: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyzing each dataset\n",
    "analyze_json(folder + 'train_M.json')\n",
    "analyze_json(folder + 'val_M.json')\n",
    "analyze_json(folder + 'test_M.json')\n",
    "\n",
    "analyze_json(folder + 'train_F.json')\n",
    "analyze_json(folder + 'val_F.json')\n",
    "analyze_json(folder + 'test_F.json')\n",
    "\n",
    "analyze_json(folder + 'train_mixed.json')\n",
    "analyze_json(folder + 'val_mixed.json')\n",
    "analyze_json(folder + 'test_mixed.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
